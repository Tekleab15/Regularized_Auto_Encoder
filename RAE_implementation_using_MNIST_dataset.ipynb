{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tekleab15/Regularized_Auto_Encoder/blob/main/RAE_implementation_using_MNIST_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_0jracwfGRV"
      },
      "source": [
        "  **Regularized Autoencoder - RAE Using MNIST dataset **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tllmAZV5eihF"
      },
      "source": [
        "*Implementation of RAE(Regularized Autoencoders) as per the specification on the paper THE NEURAL CODING FRAMEWORK FOR LEARNING GENERATIVE MODELS  *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syu9d7J-gnmv"
      },
      "source": [
        "Importing required libraries and methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NEVgVf9Ja__o"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape, InputLayer, BatchNormalization, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xjPF5LngyJX"
      },
      "source": [
        "Preprocess dataset according to the specification provided in the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zTka4zTrdR33"
      },
      "outputs": [],
      "source": [
        "def preprocess_dataset(x_train, x_test):\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "    x_train = (x_train > 0.5).astype('float32')\n",
        "    x_test = (x_test > 0.5).astype('float32')\n",
        "    x_train = x_train.reshape(-1, 784)\n",
        "    x_test = x_test.reshape(-1, 784)\n",
        "    return x_train, x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czqEpEYDhv-_"
      },
      "source": [
        "Loading and Preprocess the dataset from the keras datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V488hMmudXXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a5ea65d-dea1-4e5d-ec9c-66dc153e3c91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess the MNIST dataset, including labels\n",
        "(x_train_raw, y_train), (x_test_raw, y_test) = mnist.load_data()\n",
        "x_train, x_test = preprocess_dataset(x_train_raw, x_test_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmrPQlXziGMO"
      },
      "source": [
        "Designing the model Architecture as per the specification in the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JI6m5CMbdeP6"
      },
      "outputs": [],
      "source": [
        "input_shape = (784,)\n",
        "latent_dim = 20\n",
        "hidden_layer_size = 360\n",
        "\n",
        "# Encoder section\n",
        "encoder = Sequential(name=\"encoder\")\n",
        "encoder.add(InputLayer(shape=input_shape))\n",
        "encoder.add(Dense(hidden_layer_size, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.05)))\n",
        "encoder.add(BatchNormalization())\n",
        "encoder.add(Dropout(0.2))\n",
        "# encoder.add(Dense(hidden_layer_size, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.05)))\n",
        "# encoder.add(Dense(hidden_layer_size, activation='relu'))\n",
        "encoder.add(Dense(hidden_layer_size, activation='relu'))\n",
        "encoder.add(BatchNormalization())\n",
        "encoder.add(Dropout(0.2))\n",
        "encoder.add(Dense(latent_dim, activation='sigmoid'))\n",
        "\n",
        "# Decoder section\n",
        "decoder = Sequential(name=\"decoder\")\n",
        "decoder.add(InputLayer(shape=(latent_dim,)))\n",
        "# decoder.add(Dense(hidden_layer_size, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.05), kernel_regularizer=regularizers.l2(1e-6)))\n",
        "# decoder.add(Dense(hidden_layer_size, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.05), kernel_regularizer=regularizers.l2(1e-6)))\n",
        "decoder.add(Dense(hidden_layer_size, activation='relu', kernel_regularizer=regularizers.l2(1e-2)))\n",
        "decoder.add(BatchNormalization())\n",
        "decoder.add(Dropout(0.2))\n",
        "decoder.add(Dense(hidden_layer_size, activation='relu'))\n",
        "decoder.add(BatchNormalization())\n",
        "decoder.add(Dropout(0.2))\n",
        "decoder.add(Dense(input_shape[0], activation='sigmoid'))\n",
        "decoder.add(Reshape(input_shape))\n",
        "\n",
        "rae = Sequential([encoder, decoder], name=\"RAE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7THcUMKDUGiM"
      },
      "outputs": [],
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.01,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "Ol2NS7yveqEU",
        "outputId": "79e4fd32-c671-4e58-f3a7-c329e6612abf"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"RAE\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"RAE\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ encoder (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │       \u001b[38;5;34m422,660\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │       \u001b[38;5;34m423,424\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">422,660</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">423,424</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m846,084\u001b[0m (3.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">846,084</span> (3.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m843,204\u001b[0m (3.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">843,204</span> (3.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,880\u001b[0m (11.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,880</span> (11.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.005, clipnorm=5.0)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9, nesterov=True, clipnorm=5)\n",
        "rae.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "print(rae.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30AxtLBTn2kn"
      },
      "source": [
        "**Training the RAE model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDibQeTXim7v",
        "outputId": "9ca2c4d0-a7e6-42f2-c80b-3524af463edf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 39ms/step - loss: 1.0746 - val_loss: 0.8045\n",
            "Epoch 2/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.8137 - val_loss: 0.6872\n",
            "Epoch 3/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - loss: 0.7050 - val_loss: 0.6278\n",
            "Epoch 4/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - loss: 0.6473 - val_loss: 0.5784\n",
            "Epoch 5/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - loss: 0.5953 - val_loss: 0.5248\n",
            "Epoch 6/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.5297 - val_loss: 0.4561\n",
            "Epoch 7/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - loss: 0.4481 - val_loss: 0.3692\n",
            "Epoch 8/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.3671 - val_loss: 0.2977\n",
            "Epoch 9/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.3044 - val_loss: 0.2555\n",
            "Epoch 10/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 41ms/step - loss: 0.2636 - val_loss: 0.2260\n",
            "Epoch 11/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m25s\u001b[0m 56ms/step - loss: 0.2388 - val_loss: 0.2104\n",
            "Epoch 12/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 36ms/step - loss: 0.2224 - val_loss: 0.1981\n",
            "Epoch 13/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 36ms/step - loss: 0.2118 - val_loss: 0.1915\n",
            "Epoch 14/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - loss: 0.2034 - val_loss: 0.1816\n",
            "Epoch 15/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.1979 - val_loss: 0.1772\n",
            "Epoch 16/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 0.1929 - val_loss: 0.1749\n",
            "Epoch 17/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.1887 - val_loss: 0.1710\n",
            "Epoch 18/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.1854 - val_loss: 0.1669\n",
            "Epoch 19/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - loss: 0.1821 - val_loss: 0.1653\n",
            "Epoch 20/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - loss: 0.1800 - val_loss: 0.1624\n",
            "Epoch 21/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.1774 - val_loss: 0.1613\n",
            "Epoch 22/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 33ms/step - loss: 0.1753 - val_loss: 0.1586\n",
            "Epoch 23/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - loss: 0.1737 - val_loss: 0.1567\n",
            "Epoch 24/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 41ms/step - loss: 0.1719 - val_loss: 0.1546\n",
            "Epoch 25/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 33ms/step - loss: 0.1703 - val_loss: 0.1532\n",
            "Epoch 26/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - loss: 0.1685 - val_loss: 0.1517\n",
            "Epoch 27/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.1675 - val_loss: 0.1505\n",
            "Epoch 28/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - loss: 0.1657 - val_loss: 0.1489\n",
            "Epoch 29/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 34ms/step - loss: 0.1647 - val_loss: 0.1477\n",
            "Epoch 30/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - loss: 0.1635 - val_loss: 0.1465\n",
            "Epoch 31/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.1623 - val_loss: 0.1456\n",
            "Epoch 32/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 34ms/step - loss: 0.1607 - val_loss: 0.1442\n",
            "Epoch 33/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 33ms/step - loss: 0.1598 - val_loss: 0.1432\n",
            "Epoch 34/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - loss: 0.1590 - val_loss: 0.1417\n",
            "Epoch 35/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 39ms/step - loss: 0.1582 - val_loss: 0.1413\n",
            "Epoch 36/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 32ms/step - loss: 0.1574 - val_loss: 0.1413\n",
            "Epoch 37/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - loss: 0.1561 - val_loss: 0.1400\n",
            "Epoch 38/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - loss: 0.1557 - val_loss: 0.1386\n",
            "Epoch 39/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.1547 - val_loss: 0.1383\n",
            "Epoch 40/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - loss: 0.1537 - val_loss: 0.1374\n",
            "Epoch 41/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - loss: 0.1531 - val_loss: 0.1362\n",
            "Epoch 42/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - loss: 0.1524 - val_loss: 0.1356\n",
            "Epoch 43/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - loss: 0.1516 - val_loss: 0.1345\n",
            "Epoch 44/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - loss: 0.1511 - val_loss: 0.1341\n",
            "Epoch 45/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - loss: 0.1505 - val_loss: 0.1329\n",
            "Epoch 46/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 35ms/step - loss: 0.1495 - val_loss: 0.1331\n",
            "Epoch 47/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - loss: 0.1489 - val_loss: 0.1327\n",
            "Epoch 48/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - loss: 0.1483 - val_loss: 0.1319\n",
            "Epoch 49/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 34ms/step - loss: 0.1480 - val_loss: 0.1304\n",
            "Epoch 50/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - loss: 0.1471 - val_loss: 0.1297\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7ac6dbbdc610>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "rae.fit(x_train, x_train, epochs=50, batch_size=200, validation_data=(x_test, x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5TxpVlgIMpz",
        "outputId": "0e169694-0530-4c6c-9ece-6fc2dbc14916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Average Log Likelihood:  6.907468474964707\n"
          ]
        }
      ],
      "source": [
        "# Implementing and fitting the GMM model\n",
        "z_train = encoder.predict(x_train)\n",
        "gmm = GaussianMixture(n_components=75, covariance_type='full').fit(z_train)\n",
        "\n",
        "sampled_latent = gmm.sample(n_samples=5000)[0]\n",
        "generated_samples = decoder.predict(sampled_latent)\n",
        "\n",
        "log_likelihood = gmm.score_samples(z_train)\n",
        "average_log_likelihood = np.mean(log_likelihood)\n",
        "print(\"Average Log Likelihood: \", average_log_likelihood)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L21fjZuQQ-e7",
        "outputId": "49345af8-96d3-4ffe-9383-045c967f5b6a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Average Log Likelihood for Test Data:  6.39\n"
          ]
        }
      ],
      "source": [
        "# Encode test data\n",
        "z_test = encoder.predict(x_test)\n",
        "\n",
        "# Calculate the log likelihood of the latent representations\n",
        "log_likelihood_test = gmm.score_samples(z_test)\n",
        "average_log_likelihood_test = np.mean(log_likelihood_test)\n",
        "average_log_likelihood_test = round(average_log_likelihood_test,2)\n",
        "print(\"Average Log Likelihood for Test Data: \", average_log_likelihood_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ_ccwv4efcw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PHX0Va2TkdZj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b479baee-8719-42f2-b581-b981a8be073a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step\n",
            "{'MSE per Sample': 30.200000762939453, 'BCE per Sample': 101.12999725341797, 'Log-Likelihood per Sample': 6.39, 'Classification Error (%)': 14.0}\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model_per_sample(model, x_test, y_test, gmm):\n",
        "    reconstructions = model.predict(x_test)\n",
        "    bce_mean = tf.keras.losses.BinaryCrossentropy()(x_test, reconstructions).numpy()\n",
        "    mse_mean = tf.keras.losses.MeanSquaredError()(x_test, reconstructions).numpy()\n",
        "    bce_per_sample = bce_mean * x_test.shape[1]\n",
        "    bce_per_sample = round(bce_per_sample,2)\n",
        "    mse_per_sample = mse_mean * x_test.shape[1]\n",
        "    mse_per_sample = round(mse_per_sample,2)\n",
        "\n",
        "    z_test = encoder.predict(x_test)\n",
        "    z_train = encoder.predict(x_train)\n",
        "    z_train = z_train / np.linalg.norm(z_train, axis=1, keepdims=True)\n",
        "    z_test = z_test / np.linalg.norm(z_test, axis=1, keepdims=True)\n",
        "\n",
        "    log_reg = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
        "    log_reg.fit(z_train, y_train)\n",
        "    y_pred = log_reg.predict(z_test)\n",
        "    classification_error = 100 * (1 - np.mean(y_pred == y_test))\n",
        "    classification_error = round(classification_error,2)\n",
        "\n",
        "    return {\n",
        "        \"MSE per Sample\": float(mse_per_sample),\n",
        "        \"BCE per Sample\": float(bce_per_sample),\n",
        "        \"Log-Likelihood per Sample\": float(average_log_likelihood_test),\n",
        "        \"Classification Error (%)\": float(classification_error),\n",
        "        # \"Generated Samples\": generated_samples\n",
        "    }\n",
        "\n",
        "evaluation_results = evaluate_model_per_sample(rae, x_test, y_test, gmm)\n",
        "print(evaluation_results)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN5Grjiqp2FGoWzdf6nGHt9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}