{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tekleab15/Regularized_Auto_Encoder/blob/main/RAE_implementation_using_MNIST_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_0jracwfGRV"
      },
      "source": [
        "  **Regularized Autoencoder - RAE Using MNIST dataset **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tllmAZV5eihF"
      },
      "source": [
        "*Implementation of RAE(Regularized Autoencoders) as per the specification on the paper THE NEURAL CODING FRAMEWORK FOR LEARNING GENERATIVE MODELS  *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syu9d7J-gnmv"
      },
      "source": [
        "Importing required libraries and methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "NEVgVf9Ja__o"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape, InputLayer, BatchNormalization, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xjPF5LngyJX"
      },
      "source": [
        "Preprocess dataset according to the specification provided in the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "zTka4zTrdR33"
      },
      "outputs": [],
      "source": [
        "def preprocess_dataset(x_train, x_test):\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "    x_train = (x_train > 0.5).astype('float32')\n",
        "    x_test = (x_test > 0.5).astype('float32')\n",
        "    x_train = x_train.reshape(-1, 784)\n",
        "    x_test = x_test.reshape(-1, 784)\n",
        "    return x_train, x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czqEpEYDhv-_"
      },
      "source": [
        "Loading and Preprocess the dataset from the keras datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "V488hMmudXXn"
      },
      "outputs": [],
      "source": [
        "# Load and preprocess the MNIST dataset, including labels\n",
        "(x_train_raw, y_train), (x_test_raw, y_test) = mnist.load_data()\n",
        "x_train, x_test = preprocess_dataset(x_train_raw, x_test_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmrPQlXziGMO"
      },
      "source": [
        "Designing the model Architecture as per the specification in the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JI6m5CMbdeP6"
      },
      "outputs": [],
      "source": [
        "input_shape = (784,)\n",
        "latent_dim = 20\n",
        "hidden_layer_size = 360\n",
        "\n",
        "# Encoder section\n",
        "encoder = Sequential(name=\"encoder\")\n",
        "encoder.add(InputLayer(shape=input_shape))\n",
        "encoder.add(Dense(hidden_layer_size, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.05)))\n",
        "encoder.add(BatchNormalization())\n",
        "encoder.add(Dropout(0.2))\n",
        "# encoder.add(Dense(hidden_layer_size, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.05)))\n",
        "# encoder.add(Dense(hidden_layer_size, activation='relu'))\n",
        "encoder.add(Dense(hidden_layer_size, activation='relu'))\n",
        "encoder.add(BatchNormalization())\n",
        "encoder.add(Dropout(0.2))\n",
        "encoder.add(Dense(latent_dim, activation='sigmoid'))\n",
        "\n",
        "# Decoder section\n",
        "decoder = Sequential(name=\"decoder\")\n",
        "decoder.add(InputLayer(shape=(latent_dim,)))\n",
        "# decoder.add(Dense(hidden_layer_size, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.05), kernel_regularizer=regularizers.l2(1e-6)))\n",
        "# decoder.add(Dense(hidden_layer_size, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.05), kernel_regularizer=regularizers.l2(1e-6)))\n",
        "decoder.add(Dense(hidden_layer_size, activation='relu', kernel_regularizer=regularizers.l2(1e-2)))\n",
        "decoder.add(BatchNormalization())\n",
        "decoder.add(Dropout(0.2))\n",
        "decoder.add(Dense(hidden_layer_size, activation='relu', kernel_regularizer=regularizers.l2(1e-2)))\n",
        "decoder.add(BatchNormalization())\n",
        "decoder.add(Dropout(0.2))\n",
        "decoder.add(Dense(input_shape[0], activation='sigmoid'))\n",
        "decoder.add(Reshape(input_shape))\n",
        "\n",
        "rae = Sequential([encoder, decoder], name=\"RAE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "7THcUMKDUGiM"
      },
      "outputs": [],
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.01,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "Ol2NS7yveqEU",
        "outputId": "3f8eeec0-09b3-4369-ec53-01e73f47c7dd"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"RAE\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"RAE\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder (\u001b[38;5;33mSequential\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │         \u001b[38;5;34m422,660\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder (\u001b[38;5;33mSequential\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │         \u001b[38;5;34m423,424\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">422,660</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">423,424</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m846,084\u001b[0m (3.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">846,084</span> (3.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m843,204\u001b[0m (3.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">843,204</span> (3.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,880\u001b[0m (11.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,880</span> (11.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.005, clipnorm=5.0)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9, nesterov=True, clipnorm=5)\n",
        "rae.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "print(rae.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30AxtLBTn2kn"
      },
      "source": [
        "**Training the RAE model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDibQeTXim7v",
        "outputId": "b20c9575-b836-4d6e-a802-b2b3b0a9c134"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 41ms/step - loss: 3.8930 - val_loss: 1.9043\n",
            "Epoch 2/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - loss: 1.6408 - val_loss: 1.0124\n",
            "Epoch 3/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - loss: 0.9392 - val_loss: 0.7322\n",
            "Epoch 4/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - loss: 0.7014 - val_loss: 0.6149\n",
            "Epoch 5/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - loss: 0.6000 - val_loss: 0.5310\n",
            "Epoch 6/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 40ms/step - loss: 0.5235 - val_loss: 0.4500\n",
            "Epoch 7/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 0.4411 - val_loss: 0.3682\n",
            "Epoch 8/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.3622 - val_loss: 0.3025\n",
            "Epoch 9/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 0.3022 - val_loss: 0.2586\n",
            "Epoch 10/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 43ms/step - loss: 0.2631 - val_loss: 0.2307\n",
            "Epoch 11/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 39ms/step - loss: 0.2389 - val_loss: 0.2130\n",
            "Epoch 12/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - loss: 0.2227 - val_loss: 0.2015\n",
            "Epoch 13/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.2121 - val_loss: 0.1933\n",
            "Epoch 14/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.2041 - val_loss: 0.1867\n",
            "Epoch 15/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - loss: 0.1984 - val_loss: 0.1819\n",
            "Epoch 16/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.1939 - val_loss: 0.1778\n",
            "Epoch 17/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.1896 - val_loss: 0.1744\n",
            "Epoch 18/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - loss: 0.1867 - val_loss: 0.1716\n",
            "Epoch 19/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 0.1840 - val_loss: 0.1691\n",
            "Epoch 20/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.1812 - val_loss: 0.1666\n",
            "Epoch 21/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - loss: 0.1791 - val_loss: 0.1649\n",
            "Epoch 22/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 0.1773 - val_loss: 0.1629\n",
            "Epoch 23/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - loss: 0.1753 - val_loss: 0.1612\n",
            "Epoch 24/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.1738 - val_loss: 0.1599\n",
            "Epoch 25/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 0.1727 - val_loss: 0.1582\n",
            "Epoch 26/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.1709 - val_loss: 0.1570\n",
            "Epoch 27/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.1697 - val_loss: 0.1558\n",
            "Epoch 28/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - loss: 0.1683 - val_loss: 0.1544\n",
            "Epoch 29/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - loss: 0.1677 - val_loss: 0.1536\n",
            "Epoch 30/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - loss: 0.1659 - val_loss: 0.1523\n",
            "Epoch 31/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.1652 - val_loss: 0.1513\n",
            "Epoch 32/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - loss: 0.1645 - val_loss: 0.1503\n",
            "Epoch 33/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.1635 - val_loss: 0.1494\n",
            "Epoch 34/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - loss: 0.1625 - val_loss: 0.1487\n",
            "Epoch 35/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - loss: 0.1621 - val_loss: 0.1478\n",
            "Epoch 36/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.1612 - val_loss: 0.1470\n",
            "Epoch 37/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - loss: 0.1608 - val_loss: 0.1465\n",
            "Epoch 38/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - loss: 0.1597 - val_loss: 0.1453\n",
            "Epoch 39/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - loss: 0.1595 - val_loss: 0.1451\n",
            "Epoch 40/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.1585 - val_loss: 0.1443\n",
            "Epoch 41/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - loss: 0.1577 - val_loss: 0.1435\n",
            "Epoch 42/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - loss: 0.1571 - val_loss: 0.1427\n",
            "Epoch 43/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.1567 - val_loss: 0.1420\n",
            "Epoch 44/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - loss: 0.1559 - val_loss: 0.1413\n",
            "Epoch 45/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 43ms/step - loss: 0.1551 - val_loss: 0.1408\n",
            "Epoch 46/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 37ms/step - loss: 0.1544 - val_loss: 0.1398\n",
            "Epoch 47/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.1540 - val_loss: 0.1397\n",
            "Epoch 48/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - loss: 0.1535 - val_loss: 0.1389\n",
            "Epoch 49/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 39ms/step - loss: 0.1533 - val_loss: 0.1381\n",
            "Epoch 50/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 39ms/step - loss: 0.1526 - val_loss: 0.1379\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7f42649d8f90>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "rae.fit(x_train, x_train, epochs=50, batch_size=200, validation_data=(x_test, x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5TxpVlgIMpz",
        "outputId": "f8279c1b-04c0-4c81-853a-1917b81068d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/mixture/_base.py:269: ConvergenceWarning: Best performing initialization did not converge. Try different init parameters, or increase max_iter, tol, or check for degenerate data.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Average Log Likelihood:  7.3144807655190505\n"
          ]
        }
      ],
      "source": [
        "# Implementing and fitting the GMM model\n",
        "z_train = encoder.predict(x_train)\n",
        "gmm = GaussianMixture(n_components=75, covariance_type='full').fit(z_train)\n",
        "\n",
        "sampled_latent = gmm.sample(n_samples=5000)[0]\n",
        "generated_samples = decoder.predict(sampled_latent)\n",
        "\n",
        "log_likelihood = gmm.score_samples(z_train)\n",
        "average_log_likelihood = np.mean(log_likelihood)\n",
        "print(\"Average Log Likelihood: \", average_log_likelihood)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L21fjZuQQ-e7",
        "outputId": "d27e2276-6dcc-4fa1-ed9f-bb88853354f2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "Average Log Likelihood for Test Data:  6.867544435173674\n"
          ]
        }
      ],
      "source": [
        "# Encode test data\n",
        "z_test = encoder.predict(x_test)\n",
        "\n",
        "# Calculate the log likelihood of the latent representations\n",
        "log_likelihood_test = gmm.score_samples(z_test)\n",
        "average_log_likelihood_test = np.mean(log_likelihood_test)\n",
        "print(\"Average Log Likelihood for Test Data: \", average_log_likelihood_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ_ccwv4efcw"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHX0Va2TkdZj",
        "outputId": "0a358936-92ed-47e6-ef08-5d3736d14af3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
            "{'MSE per Sample': 30.44, 'BCE per Sample': 102.37, 'Log-Likelihood per Sample': 6.87, 'Classification Error (%)': 14.16}\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model_per_sample(model, x_test, y_test, gmm):\n",
        "    reconstructions = model.predict(x_test)\n",
        "    bce_mean = tf.keras.losses.BinaryCrossentropy()(x_test, reconstructions).numpy()\n",
        "    mse_mean = tf.keras.losses.MeanSquaredError()(x_test, reconstructions).numpy()\n",
        "    bce_per_sample = bce_mean * x_test.shape[1]\n",
        "    mse_per_sample = mse_mean * x_test.shape[1]\n",
        "\n",
        "    z_test = encoder.predict(x_test)\n",
        "    z_train = encoder.predict(x_train)\n",
        "    z_train = z_train / np.linalg.norm(z_train, axis=1, keepdims=True)\n",
        "    z_test = z_test / np.linalg.norm(z_test, axis=1, keepdims=True)\n",
        "\n",
        "    log_reg = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
        "    log_reg.fit(z_train, y_train)\n",
        "    y_pred = log_reg.predict(z_test)\n",
        "    classification_error = 100 * (1 - np.mean(y_pred == y_test))\n",
        "\n",
        "    return {\n",
        "        \"MSE per Sample\": round(mse_per_sample, 2),\n",
        "        \"BCE per Sample\": round(bce_per_sample, 2),\n",
        "        \"Log-Likelihood per Sample\": round(average_log_likelihood_test, 2),\n",
        "        \"Classification Error (%)\": round(classification_error, 2),\n",
        "        # \"Generated Samples\": generated_samples\n",
        "    }\n",
        "\n",
        "evaluation_results = evaluate_model_per_sample(rae, x_test, y_test, gmm)\n",
        "print(evaluation_results)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMth2SBNJCZUlW8ZlCVQG9w",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}