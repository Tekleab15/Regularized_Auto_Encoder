{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tekleab15/Regularized_Auto_Encoder/blob/main/RAE_implementation_using_MNIST_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_0jracwfGRV"
      },
      "source": [
        "  **Regularized Autoencoder - RAE Using MNIST dataset **"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tllmAZV5eihF"
      },
      "source": [
        "*Implementation of RAE(Regularized Autoencoders) as per the specification on the paper THE NEURAL CODING FRAMEWORK FOR LEARNING GENERATIVE MODELS  *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syu9d7J-gnmv"
      },
      "source": [
        "Importing required libraries and methods"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "NEVgVf9Ja__o"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape, InputLayer, BatchNormalization, Dropout\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.mixture import GaussianMixture\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow_datasets as tfds\n",
        "from tensorflow.keras.initializers import RandomNormal\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1xjPF5LngyJX"
      },
      "source": [
        "Preprocess dataset according to the specification provided in the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "zTka4zTrdR33"
      },
      "outputs": [],
      "source": [
        "def preprocess_dataset(x_train, x_test):\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "    x_train = (x_train > 0.5).astype('float32')\n",
        "    x_test = (x_test > 0.5).astype('float32')\n",
        "    x_train = x_train.reshape(-1, 784)\n",
        "    x_test = x_test.reshape(-1, 784)\n",
        "    return x_train, x_test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "czqEpEYDhv-_"
      },
      "source": [
        "Loading and Preprocess the dataset from the keras datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "V488hMmudXXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3556323b-cd95-435b-dc38-d7de26347042"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ],
      "source": [
        "# Load and preprocess the MNIST dataset, including labels\n",
        "(x_train_raw, y_train), (x_test_raw, y_test) = mnist.load_data()\n",
        "x_train, x_test = preprocess_dataset(x_train_raw, x_test_raw)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmrPQlXziGMO"
      },
      "source": [
        "Designing the model Architecture as per the specification in the paper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JI6m5CMbdeP6"
      },
      "outputs": [],
      "source": [
        "input_shape = (784,)\n",
        "latent_dim = 20\n",
        "hidden_layer_size = 360\n",
        "\n",
        "# Encoder section\n",
        "encoder = Sequential(name=\"encoder\")\n",
        "encoder.add(InputLayer(shape=input_shape))\n",
        "encoder.add(Dense(hidden_layer_size, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.05)))\n",
        "encoder.add(BatchNormalization())\n",
        "encoder.add(Dropout(0.2))\n",
        "encoder.add(Dense(hidden_layer_size, activation='relu'))\n",
        "encoder.add(BatchNormalization())\n",
        "encoder.add(Dropout(0.2))\n",
        "encoder.add(Dense(latent_dim, activation='sigmoid'))\n",
        "\n",
        "# Decoder section\n",
        "decoder = Sequential(name=\"decoder\")\n",
        "decoder.add(InputLayer(shape=(latent_dim,)))\n",
        "decoder.add(Dense(hidden_layer_size, activation='relu', kernel_regularizer=regularizers.l2(1e-2)))\n",
        "decoder.add(BatchNormalization())\n",
        "decoder.add(Dropout(0.2))\n",
        "decoder.add(Dense(hidden_layer_size, activation='relu'))\n",
        "decoder.add(BatchNormalization())\n",
        "decoder.add(Dropout(0.2))\n",
        "decoder.add(Dense(input_shape[0], activation='sigmoid'))\n",
        "decoder.add(Reshape(input_shape))\n",
        "\n",
        "rae = Sequential([encoder, decoder], name=\"RAE\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "7THcUMKDUGiM"
      },
      "outputs": [],
      "source": [
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.01,\n",
        "    decay_steps=10000,\n",
        "    decay_rate=0.96,\n",
        "    staircase=True\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "id": "Ol2NS7yveqEU",
        "outputId": "c55b889c-7282-4998-b416-0522d972c112"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"RAE\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"RAE\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ encoder (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)             │       \u001b[38;5;34m422,660\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder (\u001b[38;5;33mSequential\u001b[0m)            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)            │       \u001b[38;5;34m423,424\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)             │       <span style=\"color: #00af00; text-decoration-color: #00af00\">422,660</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">423,424</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m846,084\u001b[0m (3.23 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">846,084</span> (3.23 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m843,204\u001b[0m (3.22 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">843,204</span> (3.22 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,880\u001b[0m (11.25 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,880</span> (11.25 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# optimizer = tf.keras.optimizers.Adam(learning_rate=0.005, clipnorm=5.0)\n",
        "optimizer = tf.keras.optimizers.SGD(learning_rate=lr_schedule, momentum=0.9, nesterov=True, clipnorm=5)\n",
        "rae.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "print(rae.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30AxtLBTn2kn"
      },
      "source": [
        "**Training the RAE model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDibQeTXim7v",
        "outputId": "0a551a2c-3ba1-4b85-a981-cdf284fa7445"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 43ms/step - loss: 1.0691 - val_loss: 0.8169\n",
            "Epoch 2/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 40ms/step - loss: 0.8121 - val_loss: 0.6947\n",
            "Epoch 3/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 41ms/step - loss: 0.7042 - val_loss: 0.6332\n",
            "Epoch 4/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - loss: 0.6463 - val_loss: 0.5842\n",
            "Epoch 5/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 0.5930 - val_loss: 0.5304\n",
            "Epoch 6/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.5256 - val_loss: 0.4456\n",
            "Epoch 7/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - loss: 0.4430 - val_loss: 0.3542\n",
            "Epoch 8/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 0.3621 - val_loss: 0.2982\n",
            "Epoch 9/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 0.3008 - val_loss: 0.2537\n",
            "Epoch 10/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - loss: 0.2618 - val_loss: 0.2279\n",
            "Epoch 11/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - loss: 0.2372 - val_loss: 0.2095\n",
            "Epoch 12/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 35ms/step - loss: 0.2220 - val_loss: 0.1952\n",
            "Epoch 13/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - loss: 0.2109 - val_loss: 0.1907\n",
            "Epoch 14/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - loss: 0.2032 - val_loss: 0.1842\n",
            "Epoch 15/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - loss: 0.1970 - val_loss: 0.1770\n",
            "Epoch 16/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 40ms/step - loss: 0.1923 - val_loss: 0.1744\n",
            "Epoch 17/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 0.1887 - val_loss: 0.1705\n",
            "Epoch 18/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.1852 - val_loss: 0.1681\n",
            "Epoch 19/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.1823 - val_loss: 0.1638\n",
            "Epoch 20/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 0.1795 - val_loss: 0.1620\n",
            "Epoch 21/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.1774 - val_loss: 0.1600\n",
            "Epoch 22/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - loss: 0.1747 - val_loss: 0.1582\n",
            "Epoch 23/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 40ms/step - loss: 0.1731 - val_loss: 0.1558\n",
            "Epoch 24/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 33ms/step - loss: 0.1713 - val_loss: 0.1544\n",
            "Epoch 25/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.1698 - val_loss: 0.1528\n",
            "Epoch 26/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - loss: 0.1676 - val_loss: 0.1511\n",
            "Epoch 27/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.1661 - val_loss: 0.1502\n",
            "Epoch 28/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 39ms/step - loss: 0.1654 - val_loss: 0.1502\n",
            "Epoch 29/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 38ms/step - loss: 0.1641 - val_loss: 0.1475\n",
            "Epoch 30/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.1629 - val_loss: 0.1458\n",
            "Epoch 31/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - loss: 0.1617 - val_loss: 0.1450\n",
            "Epoch 32/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 36ms/step - loss: 0.1606 - val_loss: 0.1440\n",
            "Epoch 33/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - loss: 0.1595 - val_loss: 0.1425\n",
            "Epoch 34/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - loss: 0.1585 - val_loss: 0.1419\n",
            "Epoch 35/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.1573 - val_loss: 0.1403\n",
            "Epoch 36/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - loss: 0.1562 - val_loss: 0.1402\n",
            "Epoch 37/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - loss: 0.1556 - val_loss: 0.1391\n",
            "Epoch 38/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - loss: 0.1545 - val_loss: 0.1380\n",
            "Epoch 39/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.1544 - val_loss: 0.1375\n",
            "Epoch 40/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - loss: 0.1532 - val_loss: 0.1365\n",
            "Epoch 41/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - loss: 0.1522 - val_loss: 0.1355\n",
            "Epoch 42/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 36ms/step - loss: 0.1516 - val_loss: 0.1342\n",
            "Epoch 43/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 38ms/step - loss: 0.1510 - val_loss: 0.1337\n",
            "Epoch 44/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.1501 - val_loss: 0.1335\n",
            "Epoch 45/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.1493 - val_loss: 0.1324\n",
            "Epoch 46/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 37ms/step - loss: 0.1488 - val_loss: 0.1315\n",
            "Epoch 47/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.1480 - val_loss: 0.1311\n",
            "Epoch 48/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 37ms/step - loss: 0.1473 - val_loss: 0.1301\n",
            "Epoch 49/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 38ms/step - loss: 0.1468 - val_loss: 0.1299\n",
            "Epoch 50/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 37ms/step - loss: 0.1462 - val_loss: 0.1298\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b3471aaf310>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "rae.fit(x_train, x_train, epochs=50, batch_size=200, validation_data=(x_test, x_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5TxpVlgIMpz",
        "outputId": "116bfc38-7b85-440a-d0a3-e459d7a00c59"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Average Log Likelihood:  6.674199779356554\n"
          ]
        }
      ],
      "source": [
        "# Implementing and fitting the GMM model\n",
        "z_train = encoder.predict(x_train)\n",
        "gmm = GaussianMixture(n_components=75, covariance_type='full').fit(z_train)\n",
        "\n",
        "sampled_latent = gmm.sample(n_samples=5000)[0]\n",
        "generated_samples = decoder.predict(sampled_latent)\n",
        "\n",
        "log_likelihood = gmm.score_samples(z_train)\n",
        "average_log_likelihood = np.mean(log_likelihood)\n",
        "print(\"Average Log Likelihood: \", average_log_likelihood)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L21fjZuQQ-e7",
        "outputId": "957c2b2f-7039-43bb-a419-ab710c5f1178"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Average Log Likelihood for Test Data:  6.17\n"
          ]
        }
      ],
      "source": [
        "# Encode test data\n",
        "z_test = encoder.predict(x_test)\n",
        "\n",
        "# Calculate the log likelihood of the latent representations\n",
        "log_likelihood_test = gmm.score_samples(z_test)\n",
        "average_log_likelihood_test = np.mean(log_likelihood_test)\n",
        "average_log_likelihood_test = round(average_log_likelihood_test,2)\n",
        "print(\"Average Log Likelihood for Test Data: \", average_log_likelihood_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZ_ccwv4efcw"
      },
      "source": [
        "**Measuring RAE errors**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mask_input(x, mask_ratio=0.5):\n",
        "    # Mask the right portion of each image.\n",
        "    x_images = x.reshape(-1, 28, 28)\n",
        "    mask = np.ones_like(x_images)\n",
        "    mask[:, :, int(28 * mask_ratio):] = 0\n",
        "    x_masked = x_images * mask\n",
        "    return x_masked.reshape(-1, 784), mask.reshape(-1, 784)\n",
        "\n",
        "def evaluate_model_per_sample(model, x_test, y_test, gmm):\n",
        "    # Standard reconstruction metrics.\n",
        "    reconstructions = model.predict(x_test)\n",
        "    bce_mean = tf.keras.losses.BinaryCrossentropy()(x_test, reconstructions).numpy()\n",
        "    mse_mean = tf.keras.losses.MeanSquaredError()(x_test, reconstructions).numpy()\n",
        "    bce_per_sample = round(bce_mean * x_test.shape[1], 2)\n",
        "    mse_per_sample = round(mse_mean * x_test.shape[1], 2)\n",
        "\n",
        "    # Log-likelihood evaluation on latent codes.\n",
        "    z_test = encoder.predict(x_test)\n",
        "    avg_loglik = round(np.mean(gmm.score_samples(z_test)), 2)\n",
        "\n",
        "    # Classification error using latent representations.\n",
        "    z_train = encoder.predict(x_train)\n",
        "    z_train_norm = z_train / np.linalg.norm(z_train, axis=1, keepdims=True)\n",
        "    z_test_norm = z_test / np.linalg.norm(z_test, axis=1, keepdims=True)\n",
        "    log_reg = LogisticRegression(max_iter=1000, solver='lbfgs')\n",
        "    log_reg.fit(z_train_norm, y_train)\n",
        "    y_pred = log_reg.predict(z_test_norm)\n",
        "    classification_error = round(100 * (1 - np.mean(y_pred == y_test)), 2)\n",
        "\n",
        "    # Masked MSE (pattern completion)\n",
        "    x_test_masked, mask = mask_input(x_test, mask_ratio=0.5)\n",
        "    corrupted_recon = model.predict(x_test_masked)\n",
        "    mse_masked = tf.keras.losses.MeanSquaredError()(x_test * (1 - mask), corrupted_recon * (1 - mask)).numpy()\n",
        "    masked_mse_per_sample = round(mse_masked * x_test.shape[1], 2)\n",
        "\n",
        "    return {\n",
        "        \"MSE per Sample\": float(mse_per_sample),\n",
        "        \"BCE per Sample\": float(bce_per_sample),\n",
        "        \"Log-Likelihood per Sample\": float(avg_loglik),\n",
        "        \"Classification Error (%)\": float(classification_error),\n",
        "        \"Masked MSE per Sample\": float(masked_mse_per_sample)\n",
        "    }\n",
        "\n",
        "evaluation_results = evaluate_model_per_sample(rae, x_test, y_test, gmm)\n",
        "print(evaluation_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CixPHS2CCoK7",
        "outputId": "60a27db0-1795-4f89-a856-d0ddc7d9765b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "{'MSE per Sample': 30.329999923706055, 'BCE per Sample': 101.2300033569336, 'Log-Likelihood per Sample': 6.17, 'Classification Error (%)': 14.21, 'Masked MSE per Sample': 41.619998931884766}\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNVW7lDXvIcdv5r+fwSk8Lx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}