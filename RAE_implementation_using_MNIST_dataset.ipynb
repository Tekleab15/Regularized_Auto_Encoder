{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO6Vl3m1nA1kaweej5/mwx/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tekleab15/Regularized_Auto_Encoder/blob/main/RAE_implementation_using_MNIST_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "  **Regularized Autoencoder - RAE Using MNIST dataset **"
      ],
      "metadata": {
        "id": "9_0jracwfGRV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Implementation of RAE(Regularized Autoencoders) as per the specification on the paper THE NEURAL CODING FRAMEWORK FOR LEARNING GENERATIVE MODELS  *"
      ],
      "metadata": {
        "id": "tllmAZV5eihF"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "NEVgVf9Ja__o"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib as plt\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Reshape, InputLayer\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.callbacks import Callback\n",
        "from sklearn.mixture import GaussianMixture\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_dataset(x_train, x_test):\n",
        "    x_train = x_train.astype('float32') / 255.0\n",
        "    x_test = x_test.astype('float32') / 255.0\n",
        "    x_train = (x_train > 0.5).astype('float32')\n",
        "    x_test = (x_test > 0.5).astype('float32')\n",
        "    x_train = x_train.reshape(-1, 784)\n",
        "    x_test = x_test.reshape(-1, 784)\n",
        "    return x_train, x_test"
      ],
      "metadata": {
        "id": "zTka4zTrdR33"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GradientClippingCallback(Callback):\n",
        "    def __init__(self, clipnorm):\n",
        "        super(GradientClippingCallback, self).__init__()\n",
        "        self.clipnorm = clipnorm\n",
        "\n",
        "    def on_batch_end(self, batch, logs=None):\n",
        "        for layer in self.model.layers:\n",
        "            if hasattr(layer, 'kernel'):\n",
        "                weights, bias = layer.get_weights()\n",
        "                weights_norm = tf.norm(weights, ord='euclidean')\n",
        "                if weights_norm > self.clipnorm:\n",
        "                    weights = weights * self.clipnorm / weights_norm\n",
        "                layer.set_weights([weights, bias])"
      ],
      "metadata": {
        "id": "OQSbNOiV-3XH"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess the MNIST dataset, including labels\n",
        "(x_train_raw, y_train), (x_test_raw, y_test) = mnist.load_data()\n",
        "x_train, x_test = preprocess_dataset(x_train_raw, x_test_raw)"
      ],
      "metadata": {
        "id": "V488hMmudXXn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8de0bae-a757-4308-b476-8a11220410ff"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape = (784,)\n",
        "latent_dim = 20\n",
        "hidden_layer_size = 360\n",
        "\n",
        "encoder = Sequential(name=\"encoder\")\n",
        "encoder.add(InputLayer(shape=input_shape))\n",
        "encoder.add(Dense(hidden_layer_size, activation='relu', kernel_initializer=RandomNormal(mean=0.0, stddev=0.05),kernel_regularizer=regularizers.l2(1e-4)))\n",
        "encoder.add(Dense(latent_dim, activation='sigmoid'))\n",
        "\n",
        "decoder = Sequential(name=\"decoder\")\n",
        "decoder.add(InputLayer(shape=(latent_dim,)))\n",
        "decoder.add(Dense(hidden_layer_size, activation='relu', kernel_regularizer=regularizers.l2(1e-4)))\n",
        "decoder.add(Dense(input_shape[0], activation='sigmoid'))\n",
        "decoder.add(Reshape(input_shape))\n",
        "\n",
        "rae = Sequential([encoder, decoder], name=\"RAE\")"
      ],
      "metadata": {
        "id": "JI6m5CMbdeP6"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001, clipnorm=1.0)\n",
        "# optimizer = tf.keras.optimizers.SGD(learning_rate=0.01, momentum=0.9)\n",
        "rae.compile(optimizer=optimizer, loss='binary_crossentropy')\n",
        "print(rae.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 210
        },
        "id": "Ol2NS7yveqEU",
        "outputId": "912c1912-be69-4941-b796-9867f91dad8a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"RAE\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"RAE\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder (\u001b[38;5;33mSequential\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m20\u001b[0m)                  │         \u001b[38;5;34m289,820\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder (\u001b[38;5;33mSequential\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m784\u001b[0m)                 │         \u001b[38;5;34m290,584\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ encoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">20</span>)                  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">289,820</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ decoder (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">784</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">290,584</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m580,404\u001b[0m (2.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">580,404</span> (2.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m580,404\u001b[0m (2.21 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">580,404</span> (2.21 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gradient_clipping_callback = GradientClippingCallback(clipnorm=5.0)\n",
        "rae.fit(x_train, x_train, epochs=50, batch_size=200, validation_data=(x_test, x_test), callbacks=[gradient_clipping_callback])\n",
        "# rae.fit(x_train, x_train, epochs=50, batch_size=256, validation_data=(x_test, x_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDibQeTXim7v",
        "outputId": "819dced7-6b07-47ca-e68a-a75c126cc4db"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 37ms/step - loss: 0.3535 - val_loss: 0.2251\n",
            "Epoch 2/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 24ms/step - loss: 0.2067 - val_loss: 0.1790\n",
            "Epoch 3/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.1750 - val_loss: 0.1614\n",
            "Epoch 4/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - loss: 0.1599 - val_loss: 0.1526\n",
            "Epoch 5/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 28ms/step - loss: 0.1526 - val_loss: 0.1464\n",
            "Epoch 6/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.1464 - val_loss: 0.1409\n",
            "Epoch 7/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 0.1408 - val_loss: 0.1357\n",
            "Epoch 8/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 0.1363 - val_loss: 0.1320\n",
            "Epoch 9/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 0.1325 - val_loss: 0.1279\n",
            "Epoch 10/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.1285 - val_loss: 0.1240\n",
            "Epoch 11/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 0.1248 - val_loss: 0.1216\n",
            "Epoch 12/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.1227 - val_loss: 0.1197\n",
            "Epoch 13/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 0.1208 - val_loss: 0.1175\n",
            "Epoch 14/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - loss: 0.1190 - val_loss: 0.1156\n",
            "Epoch 15/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.1172 - val_loss: 0.1144\n",
            "Epoch 16/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.1157 - val_loss: 0.1130\n",
            "Epoch 17/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 0.1142 - val_loss: 0.1113\n",
            "Epoch 18/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.1127 - val_loss: 0.1098\n",
            "Epoch 19/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 0.1111 - val_loss: 0.1085\n",
            "Epoch 20/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 0.1100 - val_loss: 0.1072\n",
            "Epoch 21/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.1091 - val_loss: 0.1065\n",
            "Epoch 22/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 0.1081 - val_loss: 0.1055\n",
            "Epoch 23/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - loss: 0.1070 - val_loss: 0.1046\n",
            "Epoch 24/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 0.1060 - val_loss: 0.1032\n",
            "Epoch 25/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 0.1046 - val_loss: 0.1019\n",
            "Epoch 26/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.1036 - val_loss: 0.1011\n",
            "Epoch 27/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.1026 - val_loss: 0.1005\n",
            "Epoch 28/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 26ms/step - loss: 0.1021 - val_loss: 0.0997\n",
            "Epoch 29/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - loss: 0.1015 - val_loss: 0.0988\n",
            "Epoch 30/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - loss: 0.1000 - val_loss: 0.0977\n",
            "Epoch 31/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 24ms/step - loss: 0.0990 - val_loss: 0.0968\n",
            "Epoch 32/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 0.0986 - val_loss: 0.0962\n",
            "Epoch 33/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 29ms/step - loss: 0.0977 - val_loss: 0.0955\n",
            "Epoch 34/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - loss: 0.0970 - val_loss: 0.0945\n",
            "Epoch 35/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 25ms/step - loss: 0.0960 - val_loss: 0.0937\n",
            "Epoch 36/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - loss: 0.0951 - val_loss: 0.0929\n",
            "Epoch 37/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 0.0944 - val_loss: 0.0921\n",
            "Epoch 38/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 24ms/step - loss: 0.0935 - val_loss: 0.0920\n",
            "Epoch 39/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 0.0932 - val_loss: 0.0914\n",
            "Epoch 40/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 28ms/step - loss: 0.0930 - val_loss: 0.0910\n",
            "Epoch 41/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 25ms/step - loss: 0.0925 - val_loss: 0.0906\n",
            "Epoch 42/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 29ms/step - loss: 0.0921 - val_loss: 0.0903\n",
            "Epoch 43/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 28ms/step - loss: 0.0917 - val_loss: 0.0903\n",
            "Epoch 44/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.0913 - val_loss: 0.0899\n",
            "Epoch 45/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 25ms/step - loss: 0.0911 - val_loss: 0.0893\n",
            "Epoch 46/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 29ms/step - loss: 0.0908 - val_loss: 0.0891\n",
            "Epoch 47/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 24ms/step - loss: 0.0906 - val_loss: 0.0888\n",
            "Epoch 48/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 24ms/step - loss: 0.0901 - val_loss: 0.0885\n",
            "Epoch 49/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 27ms/step - loss: 0.0902 - val_loss: 0.0880\n",
            "Epoch 50/50\n",
            "\u001b[1m300/300\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 28ms/step - loss: 0.0898 - val_loss: 0.0880\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a798aa69c90>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Implementing and fitting the GMM model\n",
        "z_train = encoder.predict(x_train)\n",
        "gmm = GaussianMixture(n_components=75, covariance_type='full').fit(z_train)\n",
        "\n",
        "sampled_latent = gmm.sample(n_samples=100)[0]\n",
        "generated_samples = decoder.predict(sampled_latent)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q5TxpVlgIMpz",
        "outputId": "354ef087-83d5-4a90-f219-ec1501cd9ea3"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "log_likelihood = gmm.score_samples(z_train)\n",
        "average_log_likelihood = np.mean(log_likelihood)\n",
        "print(\"Average Log Likelihood: \", average_log_likelihood)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUS8AfnDNqz6",
        "outputId": "db0a694a-8528-4392-ec1d-e650ebb8ec51"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Log Likelihood:  10.37270784035212\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode test data\n",
        "z_test = encoder.predict(x_test)\n",
        "\n",
        "# Calculate the log likelihood of the latent representations\n",
        "log_likelihood_test = gmm.score_samples(z_test)\n",
        "average_log_likelihood_test = np.mean(log_likelihood_test)\n",
        "print(\"Average Log Likelihood for Test Data: \", average_log_likelihood_test)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L21fjZuQQ-e7",
        "outputId": "100426b4-0437-4337-d93f-564c8a05163d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "Average Log Likelihood for Test Data:  9.886330946091821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hZ_ccwv4efcw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model_per_sample(model, x_test, y_test, gmm):\n",
        "    reconstructions = model.predict(x_test)\n",
        "    bce_mean = tf.keras.losses.BinaryCrossentropy()(x_test, reconstructions).numpy()\n",
        "    mse_mean = tf.keras.losses.MeanSquaredError()(x_test, reconstructions).numpy()\n",
        "    bce_per_sample = bce_mean * x_test.shape[1]\n",
        "    mse_per_sample = mse_mean * x_test.shape[1]\n",
        "    log_likelihood_per_sample = - bce_per_sample\n",
        "\n",
        "    z_test = encoder.predict(x_test)\n",
        "    z_train = encoder.predict(x_train)\n",
        "    z_train = z_train / np.linalg.norm(z_train, axis=1, keepdims=True)\n",
        "    z_test = z_test / np.linalg.norm(z_test, axis=1, keepdims=True)\n",
        "\n",
        "    knn = KNeighborsClassifier(n_neighbors=5)\n",
        "    knn.fit(z_train, y_train)\n",
        "    y_pred = knn.predict(z_test)\n",
        "    classification_error = 100 * (1 - np.mean(y_pred == y_test))\n",
        "\n",
        "    # Sample new data points from the GMM for evaluation\n",
        "    sampled_latent = gmm.sample(n_samples=100)[0]\n",
        "    generated_samples = decoder.predict(sampled_latent)\n",
        "\n",
        "    log_likelihood_train = gmm.score_samples(z_train)\n",
        "    mean_log_likelihood_train = np.mean(log_likelihood_train)\n",
        "\n",
        "    log_likelihood_test = gmm.score_samples(z_test)\n",
        "    mean_log_likelihood_test = np.mean(log_likelihood_test)\n",
        "\n",
        "    print(\"GMM Test likelyhood: \",round(mean_log_likelihood_test, 2), \"GMM Train likelyhood: \",round(mean_log_likelihood_train,2))\n",
        "\n",
        "    return {\n",
        "        \"MSE per Sample\": round(mse_per_sample, 2),\n",
        "        \"BCE per Sample\": round(bce_per_sample, 2),\n",
        "        \"Log-Likelihood per Sample\": round(log_likelihood_per_sample, 2),\n",
        "        \"Classification Error (%)\": round(classification_error, 2),\n",
        "        # \"Generated Samples\": generated_samples\n",
        "    }\n",
        "\n",
        "evaluation_results = evaluate_model_per_sample(rae, x_test, y_test, gmm)\n",
        "print(evaluation_results)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHX0Va2TkdZj",
        "outputId": "a06eae38-84ac-4bc1-db3e-173f5c4dc555"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n",
            "GMM Test likelyhood:  -9.61 GMM Train likelyhood:  -9.64\n",
            "{'MSE per Sample': 18.66, 'BCE per Sample': 62.38, 'Log-Likelihood per Sample': -62.38, 'Classification Error (%)': 3.84}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1mmIjbfhJErq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}